diff -purN linux-4.17.orig/drivers/net/ppp/Kconfig linux-4.17/drivers/net/ppp/Kconfig
--- linux-4.17.orig/drivers/net/ppp/Kconfig	2018-06-03 23:15:21.000000000 +0200
+++ linux-4.17/drivers/net/ppp/Kconfig	2018-06-08 15:04:23.491673024 +0200
@@ -68,6 +68,16 @@ config PPP_DEFLATE
 
 	  To compile this driver as a module, choose M here.
 
+config PPP_LZSCOMP
+	tristate "PPP LZS compression"
+	depends on PPP
+	help
+	  This enables Stac/HiFn LZS compression (RFC 1974) for PPP.
+	  The other end has to support it as well for this to 
+	  be useful.
+
+	  If unsure, say N.
+
 config PPP_FILTER
 	bool "PPP filtering"
 	depends on PPP
diff -purN linux-4.17.orig/drivers/net/ppp/lzs_comp.c linux-4.17/drivers/net/ppp/lzs_comp.c
--- linux-4.17.orig/drivers/net/ppp/lzs_comp.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-4.17/drivers/net/ppp/lzs_comp.c	2018-06-08 15:04:23.491673024 +0200
@@ -0,0 +1,1517 @@
+/* -*- mode: c; c-basic-offset: 1 -*-
+ *
+ * $Id: isdn_lzscomp.c,v 2.3 2004/10/23 12:58:21 beck Exp $
+ *
+ * PPP link compression code for Stac LZS (RFC1974) support
+ *
+ * (Copyleft) 1998 by Andre Beck <beck@ibh.de> under terms of the GPL
+ * Adapted to PPP subsystem by Christoph Schulz <fli4l@kristov.de>
+ *
+ * Originally just a RFC1974 decompressor, this module now contains
+ * a useable compressor as well, but that one is disabled by default.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <linux/init.h>
+#include <linux/string.h>
+
+#include <linux/ppp_defs.h>
+#include <linux/ppp-comp.h>
+
+#include <linux/unaligned.h>
+
+/*
+ * Values for debug:
+ * 0 - no additional debug info
+ * 1 - normal debug info
+ * 2 - redundant debug info
+ * 3 - heavy debug (packet dumps etc)
+ */
+
+static int debug = 0;
+
+/*
+ * Values for comp:
+ * 0 - do no compression at all, send uncompressed
+ * 1 - do absolute minimal compression (somewhat fast)
+ * ...
+ * 8 - do optimal compression (heavy but still useable)
+ * 9 - do ultimate compression (chews up nonsense amounts of CPU time)
+ */
+
+static int comp = 0;
+
+MODULE_AUTHOR("Andre Beck <beck@ibh.de>");
+MODULE_AUTHOR("Christoph Schulz <fli4l@kristov.de>");
+MODULE_DESCRIPTION("LZS Compression for PPP");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ppp-compress-" __stringify(CI_LZS_COMPRESS));
+
+module_param(debug, int, 0400);
+module_param(comp, int, 0400);
+
+/* LZS histories are 2048 Byte chunks of memory. We start with non-smart
+   (read slow) indexing - running pointers follow when the code is working
+   and someone actually notices its slow */
+
+#define LZS_HISTORY_SIZE	2048
+#define LZS_HISTORY_MASK	0x7ff	/* 2047 */
+#define LZS_HASHTAB_SIZE	256
+
+/* The number of bytes to compare before we consider to call memcmp(3)
+   Empirical results:
+   Linux/x86 on P54C: Appears that GNU C can optimize memcmp calls into
+   direct inline assembly instructions so nearly no call overhead is
+   there at all. The temporary manager doesn't seem to discover that
+   the results of later additions actually drop out of the repz cmpsb,
+   but hell - getting the rep is good enough. Thus we call memcmp on
+   this architecture unconditionally to save time.
+
+   Sun Ultra/gcc: memcmp has advantages, but only on long strings (this
+   is RISC after all). 32 seems to be a good value. On a pure break even
+   measurement, memcmp starts winning at around 12, so one should settle
+   for 16. I have no results for an actual SPARC Linux, though.
+
+   PPC/gcc: Pure break even measurement showed memcmp starts winning at
+   lengths of 16.
+
+   Alpha and HPPA with gcc appear to let memcmp win unconditionally. That
+   seems strange for a RISC platform, but has been cross-tested for Alpha
+   and should be tested again for PA-RISC.
+
+   Other: Not yet known.
+
+   Semantics: Set to 0 to unconditionally use memcmp(3). Set to >0 to
+              use memcmp(3) only when the string is at least that long.
+	      Undefine to completely wipe out memcmp(3) utilization.
+	      For unknown architectures, no use of memcmp(3) is the
+	      default.
+*/
+
+#if defined(__GNUC__)
+# if defined(__i386__)
+/* With GCC on i386, memcmp is intrinsic and will always be used */
+#  define LZS_MEMCMP_THRESHOLD 0
+# endif /* defined(__i386__) */
+# if defined(__alpha__)
+/* Despite it beeing counter intuitive for a RISC system, Alpha memcmp(3)
+   wins even for shortest strings - I haven't seen the code yet, but
+   seeing the timing from break even measurement, this is a special
+   string compare instruction for sure (PALcode?) */
+#  define LZS_MEMCMP_THRESHOLD 0
+# endif /* defined(__alpha__) */
+# if defined(__ppc__)
+/* With GCC on ppc, memcmp wins over C at lengths of 16 */
+#  define LZS_MEMCMP_THRESHOLD 16
+# endif /* defined(__ppc__) */
+#endif /* defined(__GNUC__) */
+
+/* Some words about the implementation of the compressor:
+   I started with brute force. This was - as expected - too slow for
+   any realworld use, the only chance to get it somewhat useful was
+   to limit search in a restrictive way. I then posted a question on
+   how to implement LZS efficient in ISO C to comp.compression. As
+   there were no immediate answers, I digged a bit on my own and found
+   out that gzip/zlib (aka "deflate") uses a hash table in its LZ77
+   stage. They generate hash chains from every 3-byte-match in the
+   input and later traverse these hash chains. Inspired by this idea
+   (which even is claimed to be patent free) I adapted the 3-byte-match
+   to a 2-byte-match scheme. The hash chains do not grow without bounds
+   as in deflate, instead I realized that I could store hash entries
+   in a fixed mapping to the history. This even had the net effect of
+   controlling LRU disposal of hash entries that are not relevant any
+   longer because this hash entry map was a ring buffer the same way the
+   history is one. This implementation performed much better than the
+   brute force one, but I still was not pleased. The code that deals
+   with the LRU aspects of the hash entries was complicated, hard to
+   read and did cost some performance.
+   I then got EMail response to my posting in comp.compression from
+   David Carr - he gave me a bunch of valueable hints during our
+   EMail conversation. The current implementation is still based on
+   the hash idea like outlined above, but modified with these hints
+   and tricks in mind:
+
+   The barrier hash
+   Instead of storing the actual value-range of indexes in the hash
+   table and hash entries and actively clean them up in the LRU case
+   as well as dealing with a NIL type index which must be faked some-
+   how because 0 is a valid index, use much larger values. In the
+   simplest case (as used here), just take unsigned longs. Of course
+   these values must be masked whenever used as an index into a table,
+   but this is necessary in surprisingly seldom cases. Most arithme-
+   tics can be done as easy as before. The greatest effect of the
+   barrier hash, however, is auto-scoping: Indexes that are no longer
+   valid can easily be determined because they leave the LZ77 window.
+   Thus both the hash table and hash entry list are invalidating them-
+   selves automatically and don't need active cleaning except when the
+   index wraps (which is quite seldom with unsigned long). Another big
+   advantage of the barrier hash is that it makes compressor state re-
+   sets very cheap. Just close the LZ77 window and move it far enough
+   forward and the hash table and entries are invalidated automatically.
+   My former implementation needed to clean out some 10K of memory in-
+   stead. As resets may occur on every small packet, this is a hell of
+   a lot more efficient. Due to the simplifications of the barrier
+   hash, the hash entries are no longer complicated compounds but just
+   a ring buffer of unsigned long "next" indexes.
+
+   The sigma buffer
+   As inspired from the good old "freeze" compressor, the sigma buffer
+   is the idea to mirror the history. If you have a mirror history
+   directly behind the real one, you can run string compares and other
+   inner loop operations without taking care about the ring buffer
+   wrapping: the operations just run into the mirror history. While
+   freeze uses a relatively short max string length and thus did not
+   mirror the complete history but just a tail (thus the name sigma
+   buffer, a ring with a tail), LZS can code 2047 byte strings and
+   I mirror the complete history (we could call it an 8-Buffer).
+
+   Memcmp
+   Another great hint from freeze was how to use memcmp(3) for the
+   string matching. If you know that you need a string match longer
+   than n and don't care about the length of the actual match if it
+   is less than n+1, you can first memcmp(histidx, inputidx, n+1) and
+   only if it succeeds count the remaining matching bytes. If the
+   memcmp doesn't succeed, the match was shorter than n+1 and thus
+   of no further interest.
+
+*/
+
+/* Chris Toreks hash function as also utilized in DB. Surprisingly
+   simple but still performs great. An option for further optimization
+   of the compressor would be to find a hash that hashes better, is
+   faster and is applied incremental. */
+
+
+#define HASHME(val, hash) ((hash<<5) + hash + val)
+
+typedef struct _lzs_hist {
+	u8 *hist;		/* LZS_HISTORY_SIZE*2 allocation (8-Buffer) */
+	u32 *hashtab;		/* LZS_HASHTAB_SIZE allocation */
+	u32 *next;		/* LZS_HISTORY_SIZE allocation hash entries */
+	u32 head;		/* current head index into history */
+	int hlen;		/* bytes valid in history so far (comp) */
+	u8 seqno;		/* next expected seqno of this history */
+	u8 expra;		/* a reset request is outstanding */
+	u8 rsid;		/* reset id used for this history */
+} LZSHist;
+
+typedef struct _lzs_hists {
+ LZSHist *hists;
+ u16 nhists;
+} LZSHists;
+
+#define LZS_HMODE_TRASH		0	/* Trash hist after every frame */
+#define LZS_HMODE_ONE		1	/* Exactly one hist */
+#define LZS_HMODE_MANY		2	/* Multiple hists */
+
+typedef struct _lzs_state {
+	LZSHists *h;		/* The allocated histories if any */
+	u32 word;		/* bit blender */
+	int left;		/* bits left in blender */
+	u8 *inbuf;		/* where we read from */
+	int inlen;
+	u8 hmode;		/* history mode (placed here for align) */
+	u8 cmode;		/* check mode (dito) */
+	u8 zstuff;		/* state of zero stuffing */
+	u8 unit;		/* CCP unit */
+	u16 ccnt;		/* Coherency Counter - Ext has only 1 hist */
+	u8 rsid;		/* Next reset id to be used */
+	u8 comp:1;		/* Flag: is this a compressor ? */
+	u8 lastinc:1;		/* Flag: was the last frame incompressible ? */
+	u8 ackrs:1;		/* Flag: ack a reset request inband (EXT) */
+	int lastvjci;		/* last VJ conn idx for trivial multihist */
+	struct compstat stats;	/* statistics sink */
+	/* more to come */
+} LZSState;
+
+static short compparms[10][2] = {
+	/* depth, maxlen */
+	{0, 0},		/* 0 Actually a special case, these parms are not used */
+	{0, 32},	/* 1 Consider only first match and max string len 32 */
+	{1, 32},	/* 2 Consider two matches */
+	{2, 64},	/* 3 You got the picture */
+	{8, 256},	/* 4 */
+	{16, 1024},	/* 5 */
+	{32, 2047},	/* 6 */
+	{64, 2047},	/* 7 */
+	{128, 2047},	/* 8 */
+	{2047, 2047}	/* 9 Full depth and max length - nonsense slow */
+};
+
+/* Alloc a bunch of hists or if this fails cleanup and return NULL */
+static LZSHists *allocHists(u16 count, int is_comp)
+{
+	LZSHists *hs;
+	LZSHist *hv;
+	int i = 0;
+	int gotall;
+
+	hs = (LZSHists *)kmalloc(sizeof(LZSHists), GFP_KERNEL);
+	if(!hs)
+		return NULL;
+
+	/* Could be more than a page */
+	hv = (LZSHist *)vmalloc(sizeof(LZSHist) * count);
+	if(!hv) {
+		kfree(hs);
+		return NULL;
+	}
+	memset(hv, 0, sizeof(LZSHist) * count);
+	while(i < count) {
+		/* 4096 is larger than a page on some systems */
+		gotall = 1;
+		hv[i].hist = (u8 *)vmalloc(LZS_HISTORY_SIZE*2);
+		if(!hv[i].hist)
+			gotall = 0;
+		if(is_comp) {
+			/* Additional data structures for the compressor */
+			if(hv[i].hist) {
+				hv[i].next = (u32 *)vmalloc(sizeof(u32) * LZS_HISTORY_SIZE);
+				if(hv[i].next) {
+					hv[i].hashtab = (u32 *)vmalloc(sizeof(u32) * LZS_HASHTAB_SIZE);
+					if(!hv[i].hashtab)
+						gotall = 0;
+				} else
+					gotall = 0;
+			}
+		}
+		if(!gotall) {
+			/* Oops - have to clean the whole mess up ... */
+			while(i-- >= 0) {
+				if(hv[i].hist)
+					vfree(hv[i].hist);
+				if(hv[i].next)
+					vfree(hv[i].next);
+				if(hv[i].hashtab)
+					vfree(hv[i].hashtab);
+			}
+			vfree(hv);
+			kfree(hs);
+			return NULL;
+		}
+		/* The first expected seqno of a history is 1 */
+		hv[i].seqno = 1;
+		if(is_comp) {
+			/* Initialize next buffer and hash table to 0 (hist doesn't need this) */
+			memset(hv[i].next, 0, sizeof(u32) * LZS_HISTORY_SIZE);
+			memset(hv[i].hashtab, 0, sizeof(u32) * LZS_HASHTAB_SIZE);
+			/* Initialize history head to 2048 (so 0 is out of scope) */
+			hv[i].head = LZS_HISTORY_SIZE;
+		}
+		i++;
+	}
+	/* We got through getting all the mem - link it and return */
+	hs->hists = hv;
+	hs->nhists = count;
+	return hs;
+}
+
+static void freeHists(LZSHists *hs)
+{
+	int i;
+	for(i=0; i<hs->nhists; i++) {
+		if(hs->hists[i].hashtab)
+			vfree(hs->hists[i].hashtab);
+		if(hs->hists[i].next)
+			vfree(hs->hists[i].next);
+		vfree(hs->hists[i].hist);
+	}
+	vfree(hs->hists);
+	kfree(hs);
+}
+
+static void resetCompHist(LZSState *s, LZSHist *h)
+{
+	/* Reset the compressor state */
+	u32 oldhead = h->head;
+
+	h->hlen = 0;
+
+	/* Use the barrier hash to invalidate the whole history in a hatch. It just
+	   moves all current indices beyond the barrier. Without this nice trick
+	   we would have to zero out approx. 10K memory - thanks David ;) */
+	h->head += LZS_HISTORY_SIZE;
+
+	if(h->head < oldhead) {
+		/* We wrapped around index space. Make sure all hash table entries are
+		   invalidated - it is unlikely that they survived a full iteration
+		   about 2^32, but not impossible. For instance, it requires just
+		   two million uncompressible packets which cause a call to this
+		   function to wrap the space - certainly possible. */
+		h->head = LZS_HISTORY_SIZE;
+		memset(h->hashtab, 0, sizeof(u32) * LZS_HASHTAB_SIZE);
+	 }
+}
+
+/**
+ *	lzs_comp_stats - return compression statistics for a compressor
+ *		or decompressor.
+ *	@arg:	pointer to private space for the (de)compressor
+ *	@stats:	pointer to a struct compstat to receive the result.
+ */
+static void lzs_comp_stats(void *arg, struct compstat *stats)
+{
+	LZSState *s = (LZSState *)arg;
+
+	*stats = s->stats;
+}
+
+/**
+ *	lzs_comp_reset - reset a previously-allocated compressor.
+ *	@arg:	pointer to private state for the compressor.
+ *
+ *	This clears the history for the compressor and makes it
+ *	ready to start emitting a new compressed stream.
+ */
+static void lzs_comp_reset(void *arg)
+{
+	LZSState *s = (LZSState *)arg;
+
+	switch(s->cmode) {
+	case LZS_CMODE_SEQNO:
+		resetCompHist(s, &s->h->hists[0]);
+		break;
+	default:
+		printk(KERN_INFO "lzs_comp_reset: cmode %d NYI - reset ignored\n", s->cmode);
+		break;
+	}
+}
+
+/**
+ *	lzs_decomp_reset - reset a previously-allocated decompressor.
+ *	@arg:	pointer to private state for the decompressor.
+ *
+ *	This clears the history for the decompressor and makes it
+ *	ready to receive a new compressed stream.
+ */
+static void lzs_decomp_reset(void *arg)
+{
+	LZSState *s = (LZSState *)arg;
+
+	switch(s->cmode) {
+	case LZS_CMODE_SEQNO:
+		s->h->hists[0].expra = 0;
+		break;
+	default:
+		printk(KERN_INFO "lzs_decomp_reset: cmode %d NYI - reset ignored\n", s->cmode);
+		break;
+	}
+}
+
+/**
+ *	lzs_alloc - allocate space for a compressor or decompressor.
+ *	@options: pointer to CCP option data
+ *	@opt_len: length of the CCP option at @options.
+ *	@is_comp: 1 if compressor is to be allocated, 0 otherwise
+ *
+ *	The @options pointer points to the a buffer containing the
+ *	CCP option data for the compression being negotiated.  It is
+ *	formatted according to RFC1974, and describes the history number
+ *	as well as the check mode.
+ *
+ *	Returns the pointer to the private state for the (de)compressor,
+ *	or NULL if we could not allocate enough memory.
+ */
+static void *lzs_alloc(unsigned char *options, int opt_len, int is_comp)
+{
+	u8 cmode;
+	u16 nhists;
+	LZSState *s;
+
+	if(opt_len != CILEN_LZS_COMPRESS ||
+	   options[0] != CI_LZS_COMPRESS ||
+	   options[1] != CILEN_LZS_COMPRESS)
+		return NULL;
+
+	/* We need 2 configuration options: The number of histories and the
+	check mode to use. The number is a short - we pass it in big endian */
+
+	nhists = (options[2] << 8) | options[3];
+	cmode = options[4];
+
+	if(debug)
+		printk(KERN_DEBUG "lzs_alloc: hists %d cmode %d\n", nhists, cmode);
+
+	if(nhists > 1) {
+		printk(KERN_WARNING "lzs_alloc: multiple histories not supported\n");
+		return NULL;
+	}
+
+	if(cmode != LZS_CMODE_SEQNO) {
+		printk(KERN_WARNING "lzs_alloc: cmode %d not supported\n", cmode);
+		return NULL;
+	}
+
+	/* Allocate the state */
+
+	s = (LZSState *)kmalloc(sizeof(LZSState), GFP_KERNEL);
+	if(!s)
+		return NULL;
+
+	memset(s, 0, sizeof(LZSState));
+
+	if(debug) {
+		if (is_comp)
+			printk(KERN_DEBUG "lzs_alloc: Allocating compressor\n");
+		else
+			printk(KERN_DEBUG "lzs_alloc: Allocating decompressor\n");
+	}
+	s->comp = is_comp;
+	if(!is_comp || comp) {
+		s->hmode = LZS_HMODE_ONE;
+		switch(nhists) {
+		case 0:
+			s->hmode = LZS_HMODE_TRASH;
+			/* We still need a hist here _during_ the packet (de)compression */
+			/* This branch intentionally falls through */
+		case 1:
+			s->h = allocHists(1, s->comp);
+			if(!s->h) {
+				printk(KERN_WARNING "lzs_alloc: history - out of memory\n");
+				kfree(s);
+				return NULL;
+			}
+			break;
+		default:
+#if 0
+			s->hmode = LZS_HMODE_MANY;
+			s->h = allocHists(nhists, s->comp);
+			if(!s->h) {
+				printk(KERN_WARNING "lzs_alloc: %d histories - out of memory\n", nhists);
+				kfree(s);
+				return NULL;
+			}
+			break;
+#else
+			return NULL;
+#endif
+		}
+		if(debug)
+			printk(KERN_DEBUG "lzs_alloc: state successfully allocated\n");
+	} else {
+		printk(KERN_DEBUG "lzs_alloc: No allocations (compressor disabled)\n");
+	}
+
+	s->cmode = cmode;
+	s->lastvjci = 256;
+
+	return s;
+}
+
+/**
+ *	lzs_comp_alloc - allocate space for a compressor.
+ *	@options: pointer to CCP option data
+ *	@opt_len: length of the CCP option at @options.
+ *
+ *	The @options pointer points to the a buffer containing the
+ *	CCP option data for the compression being negotiated.  It is
+ *	formatted according to RFC1974, and describes the history number
+ *	as well as the check mode.
+ *
+ *	Returns the pointer to the private state for the compressor,
+ *	or NULL if we could not allocate enough memory.
+ */
+static void *lzs_comp_alloc(unsigned char *options, int opt_len)
+{
+	return lzs_alloc(options, opt_len, 1);
+}
+
+/**
+ *	lzs_decomp_alloc - allocate space for a decompressor.
+ *	@options: pointer to CCP option data
+ *	@opt_len: length of the CCP option at @options.
+ *
+ *	The @options pointer points to the a buffer containing the
+ *	CCP option data for the compression being negotiated.  It is
+ *	formatted according to RFC1974, and describes the history number
+ *	as well as the check mode.
+ *
+ *	Returns the pointer to the private state for the decompressor,
+ *	or NULL if we could not allocate enough memory.
+ */
+static void *lzs_decomp_alloc(unsigned char *options, int opt_len)
+{
+	return lzs_alloc(options, opt_len, 0);
+}
+
+/**
+ *	lzs_free - free the memory used by a compressor or decompressor
+ *	@arg:	pointer to the private state for the (de)compressor.
+ */
+static void lzs_free(void *arg)
+{
+	LZSState *s = (LZSState *)arg;
+
+	if (s) {
+		if(s->h) {
+			if(debug) {
+				printk(KERN_DEBUG "lzs_free: freeing %d histories\n", s->h->nhists);
+			}
+			freeHists(s->h);
+		}
+		if(debug) {
+			printk(KERN_DEBUG "lzs_free: freeing state\n");
+		}
+		kfree(s);
+	}
+}
+
+static int lzs_init(void *arg, unsigned char *options, int opt_len,
+		    int unit, int hdrlen, int debug)
+{
+	u16 nhists;
+	u8 cmode;
+	LZSState *s = (LZSState *)arg;
+
+	if (opt_len < CILEN_LZS_COMPRESS ||
+	    options[0] != CI_LZS_COMPRESS ||
+	    options[1] != CILEN_LZS_COMPRESS)
+		return 0;
+
+	nhists = (options[2] << 8) | options[3];
+	cmode = options[4];
+
+	if(debug)
+		printk(KERN_DEBUG "lzs_init: hists %d cmode %d\n", nhists, cmode);
+
+	if(nhists > 1) {
+		printk(KERN_WARNING "lzs_init: multiple histories not supported\n");
+		return 0;
+	}
+
+	if(cmode != LZS_CMODE_SEQNO) {
+		printk(KERN_WARNING "lzs_init: cmode %d not supported\n", cmode);
+		return 0;
+	}
+
+	s->unit = unit;
+
+	return 1;
+}
+
+/**
+ *	lzs_comp_init - initialize a previously-allocated compressor.
+ *	@arg:	pointer to the private state for the compressor
+ *	@options: pointer to the CCP option data describing the
+ *		compression that was negotiated with the peer
+ *	@opt_len: length of the CCP option data at @options
+ *	@unit:	PPP unit number for diagnostic messages
+ *	@hdrlen: ignored (present for backwards compatibility)
+ *	@debug:	debug flag; if non-zero, debug messages are printed.
+ *
+ *	The CCP options described by @options must match the options
+ *	specified when the compressor was allocated.  The compressor
+ *	history is reset.  Returns 0 for failure (CCP options don't
+ *	match) or 1 for success.
+ */
+static int lzs_comp_init(void *arg, unsigned char *options, int opt_len,
+			 int unit, int hdrlen, int debug)
+{
+	return lzs_init(arg, options, opt_len, unit, hdrlen, debug);
+}
+
+/**
+ *	lzs_init - initialize a previously-allocated decompressor.
+ *	@arg:	pointer to the private state for the decompressor
+ *	@options: pointer to the CCP option data describing the
+ *		compression that was negotiated with the peer
+ *	@opt_len: length of the CCP option data at @options
+ *	@unit:	PPP unit number for diagnostic messages
+ *	@hdrlen: ignored (present for backwards compatibility)
+ *	@mru:	maximum length of decompressed packets
+ *	@debug:	debug flag; if non-zero, debug messages are printed.
+ *
+ *	The CCP options described by @options must match the options
+ *	specified when the decompressor was allocated.  Returns 0 for
+ *	failure (CCP options don't match) or 1 for success.
+ */
+static int lzs_decomp_init(void *arg, unsigned char *options, int opt_len,
+			   int unit, int hdrlen, int mru, int debug)
+{
+	return lzs_init(arg, options, opt_len, unit, hdrlen, debug);
+}
+
+/* Compression stuff starts here, helper functions first */
+
+/* An index is valid if it is in the current range of the history */
+static int __inline validIndex(LZSHist *h, u32 ix)
+{
+	return ((ix < h->head) && (ix >= (h->head - h->hlen)));
+}
+
+/* Add a new 2-byte-sequence to our hash infrastructure */
+static void __inline addhash(LZSHist *h)
+{
+	/* We will go to next[h->head - 1] because we have a fixed mapping */
+	register int index = (h->head - 1) & LZS_HISTORY_MASK;
+	register u8 hash;
+	register u8 *p;
+
+	hash = 0;
+	p = &h->hist[index];
+	/* We can run through thanks to the 8-buffer (history mirror) */
+	hash = HASHME(*p++, hash);
+	hash = HASHME(*p, hash);
+
+	/* Loop ourselfs into the current hash chain for hash */
+	h->next[index] = h->hashtab[hash];
+	h->hashtab[hash] = h->head - 1;
+}
+
+/* Zap one byte over to the history */
+static void __inline putHistByte(LZSHist *h, u8 byte)
+{
+	int hix = h->head & LZS_HISTORY_MASK;
+	/* Feed the real history */
+	h->hist[hix] = byte;
+	/* Feed the mirror history (8-buffer) */
+	h->hist[hix + LZS_HISTORY_SIZE] = byte;
+	/* Increase valid range. Actually, the valid range is 2048. If the hist
+	is full, head points to the location where the next byte will be written
+	but this location still contains the oldest byte in the history. We
+	just ignore this fact, for a simple reason: we cannot encode an offset
+	of 2048. When we cannot encode it, it makes no sense to look if a match
+	is there at offset 2048, and the oldest one we care about is 2047. */
+	if(h->hlen < (LZS_HISTORY_SIZE - 1))
+		h->hlen++;
+	if(h->hlen > 1) {
+		/* We have at least 2 bytes starting at head-1 - add a hash table
+		entry for them */
+		addhash(h);
+	}
+
+	/* Move scope forward */
+	h->head++;
+
+	/* We just incremented and next check whether the value became zero.
+	This should optimize to a single branch-equal on any decent pro-
+	cessor. But x86 can always surprise you ... */
+
+	/* Did we wrap around our index space ? */
+	if(!(h->head)) {
+		/* We wrapped. It is very unlikely but still possible for us to find
+		entries in the hash table that are left over from a former trip
+		through index space. Make sure they are wiped out. */
+		h->head = 2048;
+		h->hlen = 0;
+		memset(h->hashtab, 0, sizeof(u32) * LZS_HASHTAB_SIZE);
+	}
+}
+
+/* Shift multiple bytes from inbuf to the history */
+static void __inline putHistBytes(LZSHist *h, u8 *buf, int len)
+{
+	while(len--)
+		putHistByte(h, *buf++);
+}
+
+/* Put some bits onto the output stream */
+static int __inline putBits(LZSState *s, unsigned char **obuf, int *ofree, u32 bits,
+			     int len)
+{
+	u8 byte;
+
+	s->word <<= len;
+	s->word |= bits;
+	s->left += len;
+	while(s->left >= 8) {
+		s->left -= 8;
+		byte = s->word >> (s->left);
+		if(*ofree > 0) {
+			*(*obuf)++ = byte;
+			--*ofree;
+		}
+		else {
+			return 0;
+		}
+	}
+	
+	return 1;
+}
+
+static int __inline putLiteralByte(LZSState *s, unsigned char **obuf, int *ofree,
+				    u8 byte)
+{
+	if (!putBits(s, obuf, ofree, 0, 1))
+		return 0;
+	return putBits(s, obuf, ofree, byte, 8);
+}
+
+static int __inline putCompressedString(LZSState *s, LZSHist *h,
+					unsigned char **obuf, int *ofree,
+					u32 index, int len)
+{
+	u32 offs = (h->head - index) & LZS_HISTORY_MASK;
+
+	if(offs < 128) {
+		/* Deploy a seven bit offset */
+		if (!putBits(s, obuf, ofree, 3, 2))
+			return 0;
+		if (!putBits(s, obuf, ofree, offs, 7))
+			return 0;
+	} else {
+		/* Deploy an eleven bit offset */
+		if (!putBits(s, obuf, ofree, 2, 2))
+			return 0;
+		if (!putBits(s, obuf, ofree, offs, 11)) /* Blender is now 32bit */
+			return 0;
+	}
+
+	switch(len) {
+	case 2:
+		return putBits(s, obuf, ofree, 0, 2);
+	case 3:
+		return putBits(s, obuf, ofree, 1, 2);
+	case 4:
+		return putBits(s, obuf, ofree, 2, 2);
+	case 5:
+		return putBits(s, obuf, ofree, 12, 4);
+	case 6:
+		return putBits(s, obuf, ofree, 13, 4);
+	case 7:
+		return putBits(s, obuf, ofree, 14, 4);
+	default:
+		len -= 8;
+		if (!putBits(s, obuf, ofree, 15, 4))
+			return 0;
+		while(len >= 15) {
+			if (!putBits(s, obuf, ofree, 15, 4))
+				return 0;
+			len -= 15;
+		}
+		return putBits(s, obuf, ofree, len, 4);
+	}
+}
+
+/* Return actual length of a match (new optimized version) */
+static int __inline getMatchLength(LZSState *s, LZSHist *h, u32 ix, int minlen)
+{
+	register int len = 0;
+	register int tlen;
+	register u8 *inbuf = s->inbuf;
+	register u8 *hbuf;
+
+	/* We return the length of a match between the input buffer and the
+	   history at index ix provided that the length of this match is at
+	   least minlen. If it isn't, the caller doesn't care about the actual
+	   value and we can return 0. This allows us to call memcmp(3) for
+	   a more performant test. */
+
+	/* Constrain our test to the number of relevant bytes */
+	tlen = h->head - ix;
+	tlen = compparms[comp][1] < tlen ? compparms[comp][1] : tlen;
+	tlen = s->inlen < tlen ? s->inlen : tlen;
+
+	if(tlen < minlen)
+		/* Won't give a longer match anyway - ignore */
+		return 0;
+
+	/* Get start position in our history */
+	hbuf = &h->hist[ix & LZS_HISTORY_MASK];
+
+#ifdef LZS_MEMCMP_THRESHOLD
+	/* We use memcmp(3) at all */
+#if LZS_MEMCMP_THRESHOLD
+	/* We use it only when the minlen exceeds a threshold */
+
+	if(minlen > LZS_MEMCMP_THRESHOLD) {
+
+#endif /* LZS_MEMCMP_THRESHOLD */
+
+	/* If the two strings are not equal up to minlen, there will be no longer
+	   match than minlen and we can return 0 as well. */
+	if(memcmp(hbuf, inbuf, minlen))
+		return 0;
+
+	/* Ok, they are equal so far - the rest is done as usual */
+	hbuf += minlen;
+	inbuf += minlen;
+	tlen -= minlen;
+	len += minlen;
+	/* Seen the overhead above ? Together with general call overhead, this is
+	   why we are using a threshold for really calling memcmp(3). Some archi-
+	   tectures use memcmp(3) implementations that perform great, but need
+	   at least a long- or even octaword to actually show up with a gain. */
+
+#if LZS_MEMCMP_THRESHOLD
+
+	}
+
+#endif /* LZS_MEMCMP_THRESHOLD */
+#endif /* defined(LZS_MEMCMP_THRESHOLD) */
+
+	while(tlen-- && (*hbuf++ == *inbuf++))
+		len++;
+
+	return len;
+}
+
+/**
+ *	lzs_compress - compress a PPP packet with Stac LZS compression.
+ *	@arg:	pointer to private state for the compressor
+ *	@rptr:	uncompressed packet (input)
+ *	@obuf:	compressed packet (output)
+ *	@isize:	size of uncompressed packet
+ *	@osize:	space available at @obuf
+ *
+ *	Returns the length of the compressed packet, or 0 if the
+ *	packet is incompressible.
+ */
+static int lzs_compress(void *state, unsigned char *ibuf, unsigned char *obuf, 
+			int isize, int osize)
+{
+	/* The heart of the compression is here */
+
+	register LZSState *s = (LZSState *)state;
+	register LZSHist *h;
+
+	u16 hi = 1;
+	register int llen, nlen, retry;
+	register u32 hidx, lidx, next;
+	register u8 hash;
+	int proto, ofree, olen;
+
+	/* Prefill statistics for the case of sending uncompressed - this will then
+	   be used if any of the following return 0 statements hit */
+
+	s->stats.in_count += isize;
+	s->stats.bytes_out += isize;
+	s->stats.inc_bytes += isize;
+	s->stats.inc_packets++;
+	s->stats.unc_bytes += isize;
+	s->stats.unc_packets++;
+
+	if(!comp) {
+		if(debug > 1)
+			printk(KERN_DEBUG "lzs_compress: leaving as is\n");
+		return 0;
+	}
+
+	proto = PPP_PROTOCOL(ibuf);
+	if(proto < 0x21 || proto > 0xf9 || !(proto & 0x1)) {
+		printk(KERN_DEBUG "lzs_compress: called with %04x\n", proto);
+		return 0;
+	}
+
+	obuf[0] = PPP_ADDRESS(ibuf);
+	obuf[1] = PPP_CONTROL(ibuf);
+	put_unaligned_be16(PPP_COMP, obuf + 2);
+	obuf += PPP_HDRLEN;
+	ofree = osize - PPP_HDRLEN;
+
+	/* Step 2 - initialize some values for compression. First of all, find
+	   the history we compress against. */
+
+	h = &s->h->hists[hi - 1];
+	s->word = s->left = 0;
+
+	switch(s->cmode) {
+	case LZS_CMODE_NONE:
+		/* Nothing */
+		break;
+	case LZS_CMODE_SEQNO:
+		/* One byte */
+		*obuf++ = h->seqno++;
+		--ofree;
+		break;
+	default:
+		/* Still to be implemented */
+		printk(KERN_WARNING "lzsComp: cmode %d NYI (sending as is)\n", s->cmode);
+		return 0;
+	}
+
+	/* Step 3 - the actual compression code. Don't beat me. */
+
+	/* Start by setting our input area */
+
+	s->inbuf = ibuf + 2;
+	s->inlen = isize - 2;
+
+	while(s->inlen) {
+		/* More bytes to consume */
+		if(h->hlen < 2 || (s->inlen == 1)) {
+			/* No history to search so far or just one more byte anyway */
+			if (!putLiteralByte(s, &obuf, &ofree, *s->inbuf))
+				goto incomp;
+			putHistByte(h, *s->inbuf);
+			s->inlen--;
+			s->inbuf++;
+			continue;
+		}
+		/* Ok, we have at least 2 bytes in the history and at least two still to
+		be read. So we can start to search our hash infrastructure for this
+		particular 2-byte-sequence */
+		hash = 0;
+		hash = HASHME(s->inbuf[0], hash);
+		hash = HASHME(s->inbuf[1], hash);
+		hidx = h->hashtab[hash];
+		if(validIndex(h, hidx)) {
+			/* Seems to be something valid in the hash table. May, however, be a
+			hash clash. */
+			/* Where to try next */
+			next = h->next[hidx & LZS_HISTORY_MASK];
+			/* Where this supposed match starts */
+			lidx = hidx;
+			/* How long it is - if it is a clash, it is 0 or 1 bytes long */
+			llen = 0;
+			nlen = getMatchLength(s, h, lidx, llen + 1);
+			if(nlen > llen)
+				llen = nlen;
+			/* Is this already the best possible (remaining) match ? */
+			if(llen == s->inlen || llen >= compparms[comp][1]) {
+				/* Yeah. Just spit it out */
+				if (!putCompressedString(s, h, &obuf, &ofree, lidx, llen))
+					goto incomp;
+				putHistBytes(h, s->inbuf, llen);
+				s->inlen -= llen;
+				s->inbuf += llen;
+				continue;
+			}
+			retry = compparms[comp][0];
+			while(validIndex(h, next) && retry--) {
+				/* Traverse this hash chain and find the longest match on it */
+				hidx = next;
+				/* Climb forward */
+				next = h->next[hidx & LZS_HISTORY_MASK];
+				/* Try to find a longer match */
+				nlen = getMatchLength(s, h, hidx, llen + 1);
+				if(nlen > llen) {
+					lidx = hidx;
+					llen = nlen;
+					/* Found the best possible match ? */
+					if(llen == s->inlen || llen >= compparms[comp][1]) {
+						break;
+					}
+				}
+			}
+			/* Well, if me made it till here the longest match we found is in
+			lidx/llen. Do the right thing with it. */
+			if(llen > 1) {
+				/* Nice, got a sequence match */
+				if (!putCompressedString(s, h, &obuf, &ofree, lidx, llen))
+					goto incomp;
+				putHistBytes(h, s->inbuf, llen);
+				s->inlen -= llen;
+				s->inbuf += llen;
+			} else {
+				/* Just zap a literal byte and start over */
+				if (!putLiteralByte(s, &obuf, &ofree, *s->inbuf))
+					goto incomp;
+				putHistByte(h, *s->inbuf);
+				s->inlen--;
+				s->inbuf++;
+			}
+		} else {
+			/* Never seen this sequence, zap this byte and try with the next */
+			if (!putLiteralByte(s, &obuf, &ofree, *s->inbuf))
+				goto incomp;
+			putHistByte(h, *s->inbuf);
+			s->inlen--;
+			s->inbuf++;
+		}
+	}
+	/* Write the end marker - it is a 7 bit offset of zero */
+	if (!putBits(s, &obuf, &ofree, 0x180, 9))
+		goto incomp;
+	/* Flush last bits */
+	if (!putBits(s, &obuf, &ofree, 0, 8))
+		goto incomp;
+
+	olen = osize - ofree;
+	if(debug > 1) {
+		printk(KERN_DEBUG "lzsComp: %d in %d out - sending compressed\n",
+		       isize, olen);
+	}
+
+	/* Adapt statistics - correct the former assumption of an incompressible
+	   packet by tweaking the counters */
+
+	s->stats.bytes_out -= isize;
+	s->stats.bytes_out += olen;
+	s->stats.inc_bytes -= isize;
+	s->stats.inc_packets--;
+	s->stats.comp_bytes += olen;
+	s->stats.comp_packets++;
+
+	return olen;
+
+incomp:
+	if(debug > 1)
+		printk(KERN_DEBUG "lzs_compress: frame expands\n");
+	resetCompHist(s, h);
+	return 0;
+}
+
+/**
+ *	lzs_incomp - add incompressible input data to the history.
+ *	@arg:	pointer to private state for the decompressor
+ *	@ibuf:	pointer to input packet data
+ *	@icnt:	length of input data.
+ */
+static void lzs_incomp(void *arg, unsigned char *ibuf, int icnt)
+{
+	/* If I understand it correctly this one is called when the peer has
+	   sent a frame without compression (an incompressable one). We will
+	   update the history with the data in order to keep it in sync with
+	   the sender. It does not make any difference whether the sender knows
+	   about this, a property of LZS is that the decompressor is pretty
+	   selfcontained. */
+
+	/* Actually, the RFC states that a compressor transmitting an uncom-
+	   pressed frame MUST reset his history, thus per the RFC it would be
+	   completely irrelevant whether we feed back incomps or not. But
+	   worse I get VJ errors when feeding back (should not happen) and much
+	   less errors when not feeding back - something is wrong here (may
+	   be with may peer). Deactivated feedback so far. */
+
+	register LZSState *state = (LZSState *)arg;
+
+	int proto;
+
+	/*
+	 * Check that the protocol is one we handle.
+	 */
+	proto = PPP_PROTOCOL(ibuf);
+	if (proto > 0x3fff || proto == 0xfd || proto == 0xfb)
+		return;
+
+	/*
+	 * Update stats.
+	 */
+	state->stats.inc_bytes += icnt;
+	state->stats.inc_packets++;
+	state->stats.unc_bytes += icnt;
+	state->stats.unc_packets++;
+	state->stats.in_count += icnt;
+	state->stats.bytes_out += icnt;
+}
+
+/* Decompression stuff actually starting here. I'm not that proud of it
+   because it will not compile to highly efficient code. I've tried around
+   a bit with other paradigms (macros, inline functions with lots of pointer
+   parameters for all state variables) and they were unreadable. The current
+   one is a compromise of readability and efficiency, not the less because
+   efficiency is very processor specific (on decent processors you want
+   to utilize the whole register file for temporaries and do a lot to let
+   the optimizer find out how - but the x86 register file is a bad joke and
+   actually replaced by a quite fast L1 cache so keeping state in a small
+   struct is probably faster here - keeping more than four longs of state
+   in registers would only lead to register thrashing [give me back my 68k]).
+   Code like this should be written in assembly anyway ;) */
+
+/* Get one bit from the skb */
+static __inline u32 get1(LZSState *s)
+{
+	register u8 byte;
+	register u32 ret;
+
+	if(s->left == 0) {
+		/* Not a single bit left - get a new byte */
+		if(s->inlen) {
+			byte = *s->inbuf++;
+			s->inlen--;
+			s->word |= (byte << 8);
+			s->left = 8;
+		} else {
+			if(s->zstuff > 0) {
+				printk(KERN_INFO "lzsDecomp: Warning: stuffing zeros\n");
+				s->zstuff++;
+			} else {
+				s->zstuff = 1;
+			}
+		}
+	}
+	ret = s->word & 0x8000;
+	s->word <<= 1;
+	s->left--;
+	return ret;
+}
+
+/* Common getbyte code - not used above because it is a bit more complicated
+   than the case above and get1 is called really often */
+
+static __inline void pullByte(LZSState *s)
+{
+	register u8 byte;
+
+	if(s->inlen) {
+		byte = *s->inbuf++;
+		s->inlen--;
+		s->word |= (byte << (8 - s->left));
+		s->left += 8;
+	} else {
+		/* TODO: Fix zero stuffing */
+		if(s->zstuff > 0) {
+			printk(KERN_INFO "lzsDecomp: Warning: stuffing zeros\n");
+			s->zstuff++;
+		} else {
+			s->zstuff = 1;
+		}
+	}
+}
+
+/* Get two bits */
+
+static __inline u32 get2(LZSState *s)
+{
+	register u32 ret;
+
+	if(s->left < 2)
+		/* Not enough bits left - get a new byte */
+		pullByte(s);
+	ret = s->word & 0xc000;
+	s->word <<= 2;
+	s->left -= 2;
+	return ret;
+}
+
+/* Get four bits */
+
+static __inline u32 get4(LZSState *s)
+{
+	register u32 ret;
+
+	if(s->left < 4)
+		/* Not enough bits left - get a new byte */
+		pullByte(s);
+	ret = s->word & 0xf000;
+	s->word <<= 4;
+	s->left -= 4;
+	return ret;
+}
+
+/* Get seven bits */
+
+static __inline u32 get7(LZSState *s)
+{
+	register u32 ret;
+
+	if(s->left < 7)
+		/* Not enough bits left - get a new byte */
+		pullByte(s);
+	ret = s->word & 0xfe00;
+	s->word <<= 7;
+	s->left -= 7;
+	return ret;
+}
+
+/* Get eight bits */
+
+static __inline u32 get8(LZSState *s)
+{
+	register u32 ret;
+
+	if(s->left < 8)
+		/* Not enough bits left - get a new byte */
+		pullByte(s);
+	ret = s->word & 0xff00;
+	s->word <<= 8;
+	s->left -= 8;
+	return ret;
+}
+
+/* Get eleven bits - we just get 7 and then another 4 or we had to code
+   this explicitely */
+
+static __inline u32 get11(LZSState *s)
+{
+	register u32 ret;
+
+	ret = get7(s);
+	ret |= get4(s) >> 7;
+
+	return ret;
+}
+
+/* Get the compressed length value from the input stream */
+
+static __inline short getCompLen(LZSState *s)
+{
+	register int clen, nibble;
+	/* The most probable cases are hardwired */
+	switch(get2(s)) {
+	case 0x0000:
+		return 2;
+	case 0x4000:
+		return 3;
+	case 0x8000:
+		return 4;
+	default:
+		switch(get2(s)) {
+		case 0x0000:
+			return 5;
+		case 0x4000:
+			return 6;
+		case 0x8000:
+			return 7;
+		default:
+			/* Ok, no shortcuts anymore - just get nibbles and add up */
+			clen = 8;
+			do {
+				nibble = get4(s) >> 12;
+				clen += nibble;
+				/* If we find enough nibbles to wrap something went really wrong. Or
+				   not ? Actually, lengths > 2048 could be pretty Ok, if compressing
+				   any data stream that is repetitive on a 2^n basis and very long,
+				   the compressor could theoretically issue a very long self-reference
+				   so we eventually need to remove this protection. If anyone ever sees
+				   this happen, I was too german about that. */
+				if(clen > LZS_HISTORY_SIZE)
+					return 0;
+			} while(nibble == 0xf);
+			return clen;
+		}
+	}
+}
+
+/* Output one byte to history and outbuffer */
+
+static __inline void byteOut(LZSState *s, LZSHist *h, unsigned char **obuf, int *ofree,
+			     u8 byte)
+{
+	h->hist[h->head++] = byte;
+	h->head &= LZS_HISTORY_MASK;
+	if(*ofree > 0) {
+		*(*obuf)++ = byte;
+		--*ofree;
+	}
+	else
+		printk(KERN_WARNING "lzs_decompress: output buffer full - truncated\n");
+}
+
+/* Output a bytestream referenced in the history by offs & clen */
+
+static __inline void copyComp(LZSState *s, LZSHist *h, unsigned char **obuf, int *ofree,
+			      int offs, int clen)
+{
+	register int hpos = h->head - offs;
+
+	hpos &= LZS_HISTORY_MASK;
+	while(clen--) {
+		byteOut(s, h, obuf, ofree, h->hist[hpos]);
+		hpos++;
+		hpos &= LZS_HISTORY_MASK;
+	}
+}
+
+/**
+ *	lzs_decompress - decompress a LZS-compressed packet.
+ *	@arg:	pointer to private state for the decompressor
+ *	@ibuf:	pointer to input (compressed) packet data
+ *	@isize:	length of input packet
+ *	@obuf:	pointer to space for output (decompressed) packet
+ *	@osize:	amount of space available at @obuf
+ *
+ * Because of patent problems, we return DECOMP_ERROR for errors
+ * found by inspecting the input data and for system problems, but
+ * DECOMP_FATALERROR for any errors which could possibly be said to
+ * be being detected "after" decompression.  For DECOMP_ERROR,
+ * we can issue a CCP reset-request; for DECOMP_FATALERROR, we may be
+ * infringing a patent of Motorola's if we do, so we take CCP down
+ * instead.
+ */
+static int lzs_decompress(void *arg, unsigned char *ibuf, int isize,
+			  unsigned char *obuf, int osize)
+{
+	/* Ahh. We finally got where the interesting stuff sits */
+
+	int ilen;
+	int olen;
+	int ofree;
+
+	register int offs, clen;
+	register LZSState *s = (LZSState *)arg;
+	register LZSHist *h;
+	u16 hi = 0;
+	u8 seqno;
+
+	/* Start by setting our read area */
+
+	if (isize <= PPP_HDRLEN) {
+		if (debug)
+			printk(KERN_DEBUG "lzs_decompress: short pkt (%d)\n",
+			       isize);
+		return DECOMP_ERROR;
+	}
+
+	obuf[0] = PPP_ADDRESS(ibuf);
+	obuf[1] = PPP_CONTROL(ibuf);
+	obuf += 2;
+	ofree = osize - 2;
+
+	ibuf += PPP_HDRLEN;
+	ilen = isize - PPP_HDRLEN;
+	s->inbuf = ibuf;
+	s->inlen = ilen;
+
+	/* The first option, if present, is the history number to decompress
+	   this frame against. Note that histories are counted starting at 1,
+	   while our array indexing is zero based. */
+
+	switch(s->hmode) {
+	case LZS_HMODE_TRASH:
+	case LZS_HMODE_ONE:
+		/* No history number in frame. History #1 is implicit */
+		hi = 1;
+		break;
+	case LZS_HMODE_MANY:
+		return DECOMP_ERROR;
+	}
+
+	h = &s->h->hists[hi - 1];
+
+	/* The second option, if present, is the check item according to the
+	check mode negotiated for this state */
+	switch(s->cmode) {
+	case LZS_CMODE_NONE:
+		/* Very dumb mode. Will likely go boom if sneezed onto */
+		break;
+	case LZS_CMODE_SEQNO:
+		/* Default mode. Next byte is a sequence number. Check this out */
+		if(s->inlen) {
+			seqno = *s->inbuf++;
+			s->inlen--;
+		} else {
+			if (debug)
+				printk(KERN_DEBUG "lzs_decompress: short pkt (%d)\n",
+				       isize);
+			return DECOMP_ERROR;
+		}
+
+		if(seqno != h->seqno) {
+			/* We did not expect _that_ sequence number */
+			if(debug)
+				printk(KERN_DEBUG "lzs_decompress: rcvd seq# %d exp seq# %d (sync lost)\n",
+				       seqno, h->seqno);
+			/* We MUST resync on seqno+1 */
+			seqno++;
+			h->seqno = seqno;
+			/* We have an outstanding reset ack now */
+			h->expra = 1;
+			return DECOMP_ERROR;
+		} else {
+			/* Correct seqno got - expect the next one */
+			h->seqno++;
+			/* Are we really resynced or is a reset ack still outstanding ? */
+			if(h->expra) {
+				if(debug)
+					printk(KERN_DEBUG "lzs_decompress: rcvd seq# %d but missing ResetAck\n", seqno);
+				return DECOMP_ERROR;
+			}
+		}
+		break;
+
+	default:
+		/* Still to be implemented */
+		printk(KERN_WARNING "lzs_decompress: cmode %d NYI (CCP teardown)\n", s->cmode);
+		return DECOMP_FATALERROR;
+	}
+
+	/* The real decompression code. Looks quite simple ? */
+
+	/* Initialize for decomp */
+	s->word = s->left = s->zstuff = 0;
+
+	for(;;) {
+		if(s->zstuff > 1) {
+			printk(KERN_WARNING "lzs_decompress: missing end marker - cooked one\n");
+			break;
+		}
+		if(get1(s)) {
+			/* Compressed bytes follow */
+			if(get1(s)) {
+				/* Seven bit offset follows */
+				offs = get7(s) >> 9;
+				if(!offs)
+					/* This is the end marker - a 7 bit offset of zero */
+					break;
+				/* You see the error message down there ? You actually think it is
+				   nonsense ? Look up my comment at getCompLen() and give me a hint on
+				   what you find out. */
+				if(!(clen = getCompLen(s))) {
+					printk(KERN_WARNING "lzs_decompress: length hosed - dropped\n");
+					return DECOMP_ERROR;
+				}
+				copyComp(s, h, &obuf, &ofree, offs, clen);
+			} else {
+				/* Eleven bit offset follows */
+				offs = get11(s) >> 5;
+				if(!(clen = getCompLen(s))) {
+					printk(KERN_WARNING "lzs_decompress: length hosed - dropped\n");
+					return DECOMP_ERROR;
+				}
+				copyComp(s, h, &obuf, &ofree, offs, clen);
+			}
+		} else {
+			/* Literal byte follows */
+			byteOut(s, h, &obuf, &ofree, get8(s) >> 8);
+		}
+	}
+
+	olen = osize - ofree;
+	/* Makes things more symmetric */
+	if(debug > 1)
+		printk(KERN_DEBUG "lzs_decompress: %d in %d out - decompressed\n",
+		       isize, olen);
+
+	s->stats.comp_bytes += olen;
+	s->stats.comp_packets++;
+	s->stats.in_count += isize;
+	s->stats.bytes_out += olen;
+
+	return olen;
+}
+
+/*
+ * Entry points of this shrinker
+ */
+
+static struct compressor ppp_lzs_compress = {
+	.compress_proto =	CI_LZS_COMPRESS,	/* CCP proto for PPP */
+	.comp_alloc =		lzs_comp_alloc,		/* Alloc new state */
+	.comp_free =		lzs_free,		/* Drop state */
+	.comp_init =		lzs_comp_init,		/* Initialize state */
+	.comp_reset =		lzs_comp_reset,		/* Reset state */
+	.compress =		lzs_compress,		/* Do the shrink */
+	.comp_stat =		lzs_comp_stats,		/* Get stats */
+	.decomp_alloc =		lzs_decomp_alloc,	/* Alloc new state */
+	.decomp_free =		lzs_free,		/* Drop state */
+	.decomp_init =		lzs_decomp_init,	/* Initialize state */
+	.decomp_reset =		lzs_decomp_reset,	/* Reset state */
+	.decompress =		lzs_decompress,		/* Do the other thing */
+	.incomp =		lzs_incomp,		/* Handle incompressible frame */
+	.decomp_stat =		lzs_comp_stats,		/* Get stats */
+	.owner =		THIS_MODULE
+};
+
+/*
+ * Module init: Register myself with the compressor list
+ */
+
+static int lzscomp_init(void)
+{
+	int answer = ppp_register_compressor(&ppp_lzs_compress);
+	if (answer == 0)
+		printk(KERN_INFO
+		       "PPP Stac/HiFn LZS (De)Compression registered\n");
+	if(comp < 0 || comp > 9) {
+		printk(KERN_ERR "lzs: 0 <= comp <= 9  - set to 0 (no compression)\n");
+		comp = 0;
+	}
+	return answer;
+}
+
+/*
+ * Module fini: Clear my traces
+ */
+
+void lzscomp_exit(void)
+{
+	ppp_unregister_compressor (&ppp_lzs_compress);
+}
+
+module_init(lzscomp_init);
+module_exit(lzscomp_exit);
diff -purN linux-4.17.orig/drivers/net/ppp/Makefile linux-4.17/drivers/net/ppp/Makefile
--- linux-4.17.orig/drivers/net/ppp/Makefile	2018-06-03 23:15:21.000000000 +0200
+++ linux-4.17/drivers/net/ppp/Makefile	2018-06-08 15:04:23.491673024 +0200
@@ -7,6 +7,7 @@ obj-$(CONFIG_PPP) += ppp_generic.o
 obj-$(CONFIG_PPP_ASYNC) += ppp_async.o
 obj-$(CONFIG_PPP_BSDCOMP) += bsd_comp.o
 obj-$(CONFIG_PPP_DEFLATE) += ppp_deflate.o
+obj-$(CONFIG_PPP_LZSCOMP) += lzs_comp.o
 obj-$(CONFIG_PPP_MPPE) += ppp_mppe.o
 obj-$(CONFIG_PPP_SYNC_TTY) += ppp_synctty.o
 obj-$(CONFIG_PPPOE) += pppox.o pppoe.o
diff -purN linux-4.17.orig/include/uapi/linux/ppp-comp.h linux-4.17/include/uapi/linux/ppp-comp.h
--- linux-4.17.orig/include/uapi/linux/ppp-comp.h	2018-06-03 23:15:21.000000000 +0200
+++ linux-4.17/include/uapi/linux/ppp-comp.h	2018-06-08 15:04:23.491673024 +0200
@@ -75,6 +75,28 @@
 #define DEFLATE_CHK_SEQUENCE	0
 
 /*
+ * Definitions for LZS.
+ */
+
+#define CI_LZS_COMPRESS		17
+#define CILEN_LZS_COMPRESS	5
+
+#define LZS_CMODE_NONE		0
+#define LZS_CMODE_LCB		1
+#define LZS_CMODE_CRC		2
+#define LZS_CMODE_SEQNO		3	/* MUST be implemented (default) */
+#define LZS_CMODE_EXT		4	/* Seems to be what Win0.95 uses */
+
+#define LZS_COMP_MAX_HISTS	32	/* For two-way MultiHistory */
+#define LZS_COMP_DEF_HISTS	1	/* Most likely to negotiate */
+#define LZS_DECOMP_MAX_HISTS	32	/* More is really nonsense */
+#define LZS_DECOMP_DEF_HISTS	8	/* If we get it, this may be optimal */
+
+#define LZS_HIST_BYTE1(word)   	(word>>8)	/* Just for better reading */
+#define LZS_HIST_BYTE2(word)	(word&0xff)	/* of this big endian stuff */
+#define LZS_HIST_WORD(b1,b2)	((b1<<8)|b2)	/* (network byte order rulez) */
+
+/*
  * Definitions for MPPE.
  */
 
